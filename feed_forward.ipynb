{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0832d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41585f3d",
   "metadata": {},
   "source": [
    "better ReLU for optimization, GELU sits between two linear layers, usually a linear layer followed by a nonlinear activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6efd35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d03bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x): # receives input\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3)) # mathematical approx of GELU function\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b163d3e3",
   "metadata": {},
   "source": [
    "below is the expansion and contraction of the layer outputs in feed forward from small to large to small. that's to help the input extract information, then when the matrices are optimized it helps the LLM extract relevant useful info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725280b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), # small\n",
    "            GELU(), # large\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), # small\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ec7e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = FeedForward( GPT_CONFIG_124M )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "260c5f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn( 3, 4, 768 ) #batch of 3 samples, each has 4 tokens, each embedding is 768 dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "840ee203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8724d2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1075, -0.2459, -1.0045,  ...,  0.6016, -1.5415,  1.0489],\n",
       "         [-0.2028, -0.6508, -0.5252,  ..., -0.7364,  1.3857,  0.7752],\n",
       "         [ 1.1746,  0.2382, -0.5163,  ..., -0.7314, -0.6422, -0.5772],\n",
       "         [-0.9940, -0.0569,  0.2630,  ..., -0.6018,  0.8611, -1.6849]],\n",
       "\n",
       "        [[-1.3929, -0.3243, -1.0600,  ...,  0.4747,  0.0769, -0.8110],\n",
       "         [ 0.1953,  1.4797,  0.4379,  ..., -0.4202, -1.5305, -0.9016],\n",
       "         [ 0.4767,  0.8204,  0.7494,  ...,  0.5691,  0.8258, -0.3055],\n",
       "         [ 0.6394,  0.1500, -0.7287,  ..., -0.9913, -0.8217,  0.0419]],\n",
       "\n",
       "        [[-0.7472,  2.0156,  0.8460,  ...,  1.3574, -0.2736, -0.3243],\n",
       "         [-0.0990,  0.4752,  0.8166,  ..., -1.1673,  0.7969,  1.1714],\n",
       "         [-0.6079, -0.4061, -2.6400,  ..., -0.6105, -0.5942,  0.4367],\n",
       "         [-0.6790,  0.0346, -0.1611,  ..., -0.0938, -1.6204, -0.3449]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02d3e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ff( input )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d5869ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ced27e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5231e-01,  9.3932e-02,  6.7874e-02,  ..., -2.8243e-01,\n",
       "           7.9161e-02, -1.0680e-01],\n",
       "         [ 2.9400e-01, -9.5439e-02,  6.9948e-02,  ..., -7.3149e-02,\n",
       "          -1.6704e-03, -1.4875e-01],\n",
       "         [ 1.3994e-01, -1.2535e-01,  6.5960e-02,  ..., -1.0853e-01,\n",
       "          -1.3622e-01, -1.1611e-01],\n",
       "         [-2.8352e-01,  8.8919e-02, -1.2949e-02,  ..., -6.5900e-02,\n",
       "          -2.7742e-01,  9.6893e-02]],\n",
       "\n",
       "        [[ 4.1891e-02,  4.9116e-03,  2.3661e-01,  ...,  4.7974e-02,\n",
       "          -4.4154e-02,  1.4358e-01],\n",
       "         [-8.6580e-02,  5.3038e-02, -9.2203e-02,  ...,  8.2365e-02,\n",
       "           1.7490e-02,  1.2583e-01],\n",
       "         [-2.3628e-01, -2.3842e-01,  1.7354e-01,  ..., -5.4518e-01,\n",
       "           1.5104e-01, -5.0939e-01],\n",
       "         [ 2.4275e-01,  3.9560e-01, -2.6566e-01,  ...,  2.0590e-01,\n",
       "          -1.2851e-01, -3.7776e-02]],\n",
       "\n",
       "        [[ 6.9482e-03,  1.7645e-01, -2.7216e-01,  ...,  1.1824e-01,\n",
       "          -1.2129e-01, -2.2817e-02],\n",
       "         [ 2.5770e-02, -3.7166e-02,  1.8667e-01,  ..., -4.8641e-02,\n",
       "           1.2547e-01, -1.3012e-01],\n",
       "         [-3.9821e-01,  4.7396e-02, -8.8740e-02,  ...,  3.1073e-04,\n",
       "          -6.6210e-02, -2.7078e-01],\n",
       "         [-5.7265e-02,  4.5666e-02,  2.5272e-02,  ...,  7.6459e-02,\n",
       "           3.6516e-02, -9.1549e-02]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55c60e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ff( output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "414e1dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6d668c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
