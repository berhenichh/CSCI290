{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7c33a1a1",
      "metadata": {
        "id": "7c33a1a1"
      },
      "source": [
        "# Attention with trainable weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c78b079a",
      "metadata": {
        "id": "c78b079a"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d1c0c81b",
      "metadata": {
        "id": "d1c0c81b"
      },
      "outputs": [],
      "source": [
        "inputs = torch.nn.Embedding( 4, 8 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "oNX4cULRxBVk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNX4cULRxBVk",
        "outputId": "819bafba-963e-4ddd-9d05-d9adc8d323cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.9999, -1.2737,  0.2339,  1.1430,  1.0805, -0.2544,  1.7306, -0.6830],\n",
              "        [-0.7617, -2.2307, -0.4388, -0.0068,  0.7100, -0.5587, -0.4294,  0.2109],\n",
              "        [-0.0450, -0.6184,  0.1731, -0.5922,  0.5761, -1.0463, -0.7864, -0.6586],\n",
              "        [ 0.5506, -1.1198,  0.6035,  0.6885,  1.4914, -0.5357,  0.2084,  0.8669]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "inputs = inputs.weight\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "sTBV2KZYxCLY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTBV2KZYxCLY",
        "outputId": "a9784051-43d9-4851-ec58-0a786a9c7057"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9999, -1.2737,  0.2339,  1.1430,  1.0805, -0.2544,  1.7306, -0.6830],\n",
              "        [-0.7617, -2.2307, -0.4388, -0.0068,  0.7100, -0.5587, -0.4294,  0.2109],\n",
              "        [-0.0450, -0.6184,  0.1731, -0.5922,  0.5761, -1.0463, -0.7864, -0.6586],\n",
              "        [ 0.5506, -1.1198,  0.6035,  0.6885,  1.4914, -0.5357,  0.2084,  0.8669]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "inputs = inputs.data\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "QOwlthXbxb38",
      "metadata": {
        "id": "QOwlthXbxb38"
      },
      "outputs": [],
      "source": [
        "# set dimensions\n",
        "d_in = 8\n",
        "d_out = 6\n",
        "\n",
        "# create weight matrices\n",
        "W_q = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "W_k = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "W_v = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "sNXSVRxtyUEq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNXSVRxtyUEq",
        "outputId": "78626dfb-25da-49ae-e0a3-5b0c3101c6f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.6710, -2.0310, -1.6372, -1.1939, -2.2266, -1.0149])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# choose an input vector and transform it into our query vector using W_q\n",
        "query = inputs[2] @ W_q\n",
        "query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "krMfHBPty33R",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krMfHBPty33R",
        "outputId": "e565c660-b4bf-42b1-8444-1e79a03aed9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: tensor([[-0.7485,  2.0350,  1.4101, -0.4210, -0.3566,  1.4974],\n",
            "        [-1.0786,  0.0713, -0.3865, -2.7995, -1.5736, -0.9684],\n",
            "        [-0.4913, -0.3656, -0.4984, -1.5643, -1.5112, -1.6918],\n",
            "        [ 1.2783,  1.9363,  1.6936,  0.6576,  1.4184,  2.0097]])\n",
            "Values: tensor([[-0.4124,  0.7969,  0.9632,  1.2091,  1.9863, -1.0238],\n",
            "        [-2.3077, -1.4353, -1.6752, -0.2586, -0.8632, -2.8789],\n",
            "        [-1.9008, -1.2080, -1.0207, -0.9898, -0.7862, -1.7308],\n",
            "        [ 0.4161,  3.1818,  1.4108,  1.4710,  1.3720,  0.9129]])\n"
          ]
        }
      ],
      "source": [
        "# calculate attention scores using the keys generated by W_k:\n",
        "keys = inputs @ W_k\n",
        "values = inputs @ W_v\n",
        "print(\"Keys:\", keys)\n",
        "print(\"Values:\", values )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "ZCYUxgufzYJx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCYUxgufzYJx",
        "outputId": "1a960bed-c01a-4143-95ed-8d648590f8df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ -6.1626,   9.0406,   8.8375, -13.5461])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "attention_scores = query @ keys.T\n",
        "attention_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "8E3nKiYMz-B3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E3nKiYMz-B3",
        "outputId": "23166e94-9624-468e-f5ec-1b3055a76b95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0486e-03, 5.2015e-01, 4.7875e-01, 5.1463e-05])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "attention_weights = torch.softmax( attention_scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "ivp5ajUU0hVX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivp5ajUU0hVX",
        "outputId": "66ca5d9c-3534-4833-fb72-e109344fd0d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "attention_weights.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "NDyjIXnw01bw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDyjIXnw01bw",
        "outputId": "10094491-6176-4879-dfb2-ca824e2dd35f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.1108, -1.3239, -1.3589, -0.6070, -0.8232, -2.3271])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "context_vector = attention_weights @ values\n",
        "context_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "mDJu60I-08oe",
      "metadata": {
        "id": "mDJu60I-08oe"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "nCNgyvAjDqJx",
      "metadata": {
        "id": "nCNgyvAjDqJx"
      },
      "outputs": [],
      "source": [
        "# here's a first version of a SimpleAttention class:\n",
        "\n",
        "class SimpleAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "    self.W_k = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "    self.W_v = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    queries = x @ self.W_q\n",
        "    keys = x @ self.W_k\n",
        "    values = x @ self.W_v\n",
        "    scores = queries @ keys.T\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    context = weights @ values\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "WGqfizBVGQ6H",
      "metadata": {
        "id": "WGqfizBVGQ6H"
      },
      "outputs": [],
      "source": [
        "# here's how to use this class:\n",
        "# instantiate an instance of it:\n",
        "simple = SimpleAttention( d_in = 8, d_out = 6 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "m8khSsLLGbPx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8khSsLLGbPx",
        "outputId": "f20f09e4-32ee-4690-de46-4a7924d9fa68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.6921, 0.6845, 0.6072, 0.1782, 0.2162, 0.5661],\n",
              "        [0.8071, 0.6144, 0.0525, 0.0704, 0.8423, 0.4204],\n",
              "        [0.4201, 0.7557, 0.4516, 0.6666, 0.4888, 0.2711],\n",
              "        [0.8857, 0.7941, 0.4394, 0.4806, 0.1353, 0.8625],\n",
              "        [0.1734, 0.2097, 0.1951, 0.2945, 0.2867, 0.1236],\n",
              "        [0.6912, 0.5165, 0.9224, 0.0636, 0.5102, 0.0354],\n",
              "        [0.6063, 0.7372, 0.8954, 0.5583, 0.5290, 0.9026],\n",
              "        [0.1696, 0.2644, 0.4139, 0.5451, 0.1045, 0.1209]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "simple.W_v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "IDXEWBn2GhTu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDXEWBn2GhTu",
        "outputId": "6dd13194-afef-47c8-88d3-bb220caa0cac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2017,  0.7431,  0.9255,  1.4054, -0.1963,  0.9789],\n",
              "        [-2.9610, -2.5906, -1.4886, -0.5604, -2.4817, -1.7724],\n",
              "        [-2.9415, -2.5736, -1.5034, -0.5694, -2.4537, -1.7656],\n",
              "        [ 0.4770,  1.0707,  1.1818,  1.6974, -0.0772,  1.0979]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "context_vectors = simple( inputs )\n",
        "context_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "j0J4KZOZGqfu",
      "metadata": {
        "id": "j0J4KZOZGqfu"
      },
      "outputs": [],
      "source": [
        "# here's a second version of a SimpleAttention class ;\n",
        "# it uses nn.Linear to do things more efficiently\n",
        "\n",
        "class SimpleAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    queries = self.W_q( x )\n",
        "    keys = self.W_k( x )\n",
        "    values = self.W_v( x )\n",
        "    scores = queries @ keys.T\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    context = weights @ values\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "Zki5jtLCI6Cu",
      "metadata": {
        "id": "Zki5jtLCI6Cu"
      },
      "outputs": [],
      "source": [
        "# here's how to use this class:\n",
        "# instantiate an instance of it:\n",
        "simple = SimpleAttention( d_in = 8, d_out = 6 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "k6LcTWL9I8te",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6LcTWL9I8te",
        "outputId": "f1182dbf-dd92-4ad9-fb15-cd898f3d9f59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0984,  0.2110,  0.4699, -0.3150, -0.1860, -0.3912],\n",
              "        [-0.1100,  0.2006,  0.4806, -0.2455, -0.2602, -0.4189],\n",
              "        [-0.1003,  0.2203,  0.4699, -0.3172, -0.1775, -0.3947],\n",
              "        [-0.0991,  0.2402,  0.4692, -0.3164, -0.1765, -0.4012]],\n",
              "       grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "context_vectors = simple( inputs )\n",
        "context_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "oue7IwuyI_ON",
      "metadata": {
        "id": "oue7IwuyI_ON"
      },
      "outputs": [],
      "source": [
        "# the problem with this is that each context vector uses information from ALL of the embedding vectors\n",
        "# in practice, we should only use information about the preceding embedding vectors\n",
        "# to accomplish this, we'll implement causal attention AKA masked attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "L734IABHc89l",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L734IABHc89l",
        "outputId": "4b5789aa-ff93-40f3-dffd-0471b6c0f1c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2582, 0.2558, 0.2772, 0.2087],\n",
              "        [0.2152, 0.2614, 0.3522, 0.1712],\n",
              "        [0.2511, 0.2575, 0.2659, 0.2256],\n",
              "        [0.2344, 0.2720, 0.2486, 0.2450]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# this is a hack to get some example weights to work with!\n",
        "# weights = simple( inputs )\n",
        "\n",
        "queries = simple.W_q( inputs )\n",
        "keys = simple.W_k( inputs )\n",
        "values = simple.W_v( inputs )\n",
        "scores = queries @ keys.T\n",
        "weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "SiNiJA_tdnIr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiNiJA_tdnIr",
        "outputId": "e19929a3-0ec5-4453-97b8-64695af1c7b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# note that these have already been normalized:\n",
        "weights.sum( dim=-1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "w8qwVBb3d5YE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8qwVBb3d5YE",
        "outputId": "b3eceb8b-07bd-4449-9eda-d2b42999628d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0.],\n",
              "        [1., 1., 0., 0.],\n",
              "        [1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# masking method #1\n",
        "simple_mask = torch.tril( torch.ones( weights.shape[0], weights.shape[0] ) )\n",
        "simple_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "aPN1GiEdeWq_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPN1GiEdeWq_",
        "outputId": "0ba6be0d-6bba-4085-ac9f-4953524ef4c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2582, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2152, 0.2614, 0.0000, 0.0000],\n",
              "        [0.2511, 0.2575, 0.2659, 0.0000],\n",
              "        [0.2344, 0.2720, 0.2486, 0.2450]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "masked_weights = weights*simple_mask\n",
        "masked_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "N-Ifwx0EfJs9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-Ifwx0EfJs9",
        "outputId": "742b18ae-611c-48e8-b9c4-f6b1459c1f75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2582, 0.4766, 0.7744, 1.0000], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "masked_weights.sum( dim=-1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "gbOrqXGSfbm2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbOrqXGSfbm2",
        "outputId": "9ab1e11d-c7cc-4706-ea91-9e130eab3f1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2582],\n",
              "        [0.4766],\n",
              "        [0.7744],\n",
              "        [1.0000]], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# now, we need to normalize the masked_weights so that each row has sum 1\n",
        "row_sums = masked_weights.sum( dim=-1, keepdim=True)\n",
        "row_sums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "ACdob5jyfi2P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACdob5jyfi2P",
        "outputId": "54aa8682-99ba-4cec-a411-c3ac016b3f31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "masked_weights = masked_weights / row_sums\n",
        "masked_weights.sum( dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "0_aQEYcQf4tB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_aQEYcQf4tB",
        "outputId": "48035823-c2b3-4348-dd77-83ccdb90aac5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.4515, 0.5485, 0.0000, 0.0000],\n",
              "        [0.3242, 0.3325, 0.3433, 0.0000],\n",
              "        [0.2344, 0.2720, 0.2486, 0.2450]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "masked_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "QxaUROkpgBmr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxaUROkpgBmr",
        "outputId": "74d79b36-9c7f-428d-8ad7-93c0e05e658d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1.],\n",
              "        [0., 0., 1., 1.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# masking method #2\n",
        "mask = torch.triu( torch.ones(weights.shape[0], weights.shape[0]), diagonal = 1 )\n",
        "mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "9aAkggNUhUAs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aAkggNUhUAs",
        "outputId": "d9cbe8a2-619c-4161-c1ea-e87abcd0ba18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True,  True,  True],\n",
              "        [False, False,  True,  True],\n",
              "        [False, False, False,  True],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "mask.bool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "84ev4pTZhoLD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84ev4pTZhoLD",
        "outputId": "2bf84e16-3e97-4dcd-af38-cefdd7862b0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2582, 0.2558, 0.2772, 0.2087],\n",
              "        [0.2152, 0.2614, 0.3522, 0.1712],\n",
              "        [0.2511, 0.2575, 0.2659, 0.2256],\n",
              "        [0.2344, 0.2720, 0.2486, 0.2450]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "7AW_dLvCgiA8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AW_dLvCgiA8",
        "outputId": "02a3e626-4005-413f-c06e-bf3e1bb5ee40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2582,   -inf,   -inf,   -inf],\n",
              "        [0.2152, 0.2614,   -inf,   -inf],\n",
              "        [0.2511, 0.2575, 0.2659,   -inf],\n",
              "        [0.2344, 0.2720, 0.2486, 0.2450]], grad_fn=<MaskedFillBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "weights = weights.masked_fill( mask.bool(), -torch.inf )\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "mMquJ-g1hvuq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMquJ-g1hvuq",
        "outputId": "f0115dc1-f0ca-4527-fe0c-7b8c1dbee96f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.4885, 0.5115, 0.0000, 0.0000],\n",
              "        [0.3310, 0.3331, 0.3359, 0.0000],\n",
              "        [0.2461, 0.2555, 0.2496, 0.2487]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "masked_weights = torch.softmax( weights, dim=-1 )\n",
        "masked_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "v0Rl7yaikQwW",
      "metadata": {
        "id": "v0Rl7yaikQwW"
      },
      "outputs": [],
      "source": [
        "## Dropout\n",
        "# idea: randomly select some data to leave out to avoid overfitting\n",
        "dropout = nn.Dropout( 0.5 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "Js4JQ6b9lN1p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js4JQ6b9lN1p",
        "outputId": "89f57051-d2e6-45bc-eeee-3056ec7b95a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.9769, 1.0231, 0.0000, 0.0000],\n",
              "        [0.6620, 0.0000, 0.6718, 0.0000],\n",
              "        [0.0000, 0.5111, 0.4992, 0.0000]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "dropout( masked_weights )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "lwzL1olBjA62",
      "metadata": {
        "id": "lwzL1olBjA62"
      },
      "outputs": [],
      "source": [
        "# we need to be able to give our LLM batches of input\n",
        "# for example:\n",
        "batches = torch.stack( (inputs, inputs), dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "F9pE07dKjkPS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9pE07dKjkPS",
        "outputId": "b7f4661d-948e-41d7-96e7-77faa29b95fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9999, -1.2737,  0.2339,  1.1430,  1.0805, -0.2544,  1.7306,\n",
              "          -0.6830],\n",
              "         [-0.7617, -2.2307, -0.4388, -0.0068,  0.7100, -0.5587, -0.4294,\n",
              "           0.2109],\n",
              "         [-0.0450, -0.6184,  0.1731, -0.5922,  0.5761, -1.0463, -0.7864,\n",
              "          -0.6586],\n",
              "         [ 0.5506, -1.1198,  0.6035,  0.6885,  1.4914, -0.5357,  0.2084,\n",
              "           0.8669]],\n",
              "\n",
              "        [[-0.9999, -1.2737,  0.2339,  1.1430,  1.0805, -0.2544,  1.7306,\n",
              "          -0.6830],\n",
              "         [-0.7617, -2.2307, -0.4388, -0.0068,  0.7100, -0.5587, -0.4294,\n",
              "           0.2109],\n",
              "         [-0.0450, -0.6184,  0.1731, -0.5922,  0.5761, -1.0463, -0.7864,\n",
              "          -0.6586],\n",
              "         [ 0.5506, -1.1198,  0.6035,  0.6885,  1.4914, -0.5357,  0.2084,\n",
              "           0.8669]]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "ZcupJCg5zIrL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcupJCg5zIrL",
        "outputId": "afb7bc85-174d-4912-ff4b-33824fd3fbdc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "batches.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "uP2PuQ5RiCM8",
      "metadata": {
        "id": "uP2PuQ5RiCM8"
      },
      "outputs": [],
      "source": [
        "# this class needs to handle batches of input!\n",
        "\n",
        "class CausalAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
        "    # include dropout:\n",
        "    self.dropout = nn.Dropout( dropout )\n",
        "    # use the following to manage memory efficiently:\n",
        "    self.register_buffer(\n",
        "        'mask',\n",
        "        torch.triu( torch.ones(context_length, context_length), diagonal = 1 )\n",
        "    )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    queries = self.W_q( x )\n",
        "    keys = self.W_k( x )\n",
        "    values = self.W_v( x )\n",
        "    scores = queries @ keys.transpose(1,2)\n",
        "    scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    weights = self.dropout( weights )\n",
        "    context = weights @ values\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "Tqglx-lp0TFn",
      "metadata": {
        "id": "Tqglx-lp0TFn"
      },
      "outputs": [],
      "source": [
        "# instantiate a causal attention mechanism:\n",
        "causal = CausalAttention( d_in=8, d_out=6, context_length=4, dropout=0 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "vl4s2kdd4iNi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl4s2kdd4iNi",
        "outputId": "67817166-74f9-45e4-dd94-9683f7fa47b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.5211,  1.3335,  0.0292,  0.0482, -0.0546,  1.3317],\n",
              "         [-0.1602,  0.9817,  0.3829,  0.2854,  0.0501,  1.1420],\n",
              "         [-0.1041,  0.8093,  0.4927,  0.1810, -0.0588,  0.8028],\n",
              "         [ 0.0167,  0.8670,  0.3698,  0.1432,  0.0331,  0.7435]],\n",
              "\n",
              "        [[-0.5211,  1.3335,  0.0292,  0.0482, -0.0546,  1.3317],\n",
              "         [-0.1602,  0.9817,  0.3829,  0.2854,  0.0501,  1.1420],\n",
              "         [-0.1041,  0.8093,  0.4927,  0.1810, -0.0588,  0.8028],\n",
              "         [ 0.0167,  0.8670,  0.3698,  0.1432,  0.0331,  0.7435]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "causal( batches )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "sqLa6xcW0bPw",
      "metadata": {
        "id": "sqLa6xcW0bPw"
      },
      "outputs": [],
      "source": [
        "# here's a first pass at multi-head attention\n",
        "class MultiHeadAttention( nn.Module ):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList(\n",
        "            [ CausalAttention( d_in, d_out, context_length, dropout, qkv_bias ) for _ in range(num_heads) ]\n",
        "        )\n",
        "\n",
        "    def forward( self, x ):\n",
        "        return torch.cat( [ head(x) for head in self.heads ], dim=-1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "4-NOY2s91p61",
      "metadata": {
        "id": "4-NOY2s91p61"
      },
      "outputs": [],
      "source": [
        "mha = MultiHeadAttention( d_in = 8, d_out = 6, context_length= 4, dropout=0, num_heads = 3 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "da73b4ac",
      "metadata": {
        "id": "da73b4ac"
      },
      "outputs": [],
      "source": [
        "mha_out = mha( batches )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "f1e215e8",
      "metadata": {
        "id": "f1e215e8",
        "outputId": "83cfe97c-806a-4dc0-dcbf-daf711d70157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.4208, -0.2453,  0.5383,  0.4345, -0.2936, -0.8508,  0.0527,\n",
              "          -0.0537,  1.1098,  0.3376,  0.2062,  0.2342, -1.1751, -0.3572,\n",
              "          -0.3544, -0.1014,  0.0140,  0.5943],\n",
              "         [ 1.0501,  0.0343,  0.4285,  0.2933, -0.2995, -0.2432, -0.0300,\n",
              "          -0.6992,  0.7993,  0.4846,  0.2376,  0.0484, -0.7183, -0.1285,\n",
              "           0.0313, -0.2238, -0.0749,  0.4793],\n",
              "         [ 0.8152,  0.2136,  0.3962,  0.3224, -0.1273, -0.2168, -0.2541,\n",
              "          -0.4810,  0.4369,  0.2927,  0.3138,  0.0792, -0.5553, -0.0028,\n",
              "           0.0056, -0.2044,  0.0563,  0.2354],\n",
              "         [ 0.7609,  0.2804,  0.4015,  0.2737, -0.0097, -0.0695, -0.1644,\n",
              "          -0.4264,  0.6622,  0.1981,  0.1975, -0.0442, -0.4324,  0.2567,\n",
              "           0.0029, -0.2155, -0.0194,  0.3436]],\n",
              "\n",
              "        [[ 1.4208, -0.2453,  0.5383,  0.4345, -0.2936, -0.8508,  0.0527,\n",
              "          -0.0537,  1.1098,  0.3376,  0.2062,  0.2342, -1.1751, -0.3572,\n",
              "          -0.3544, -0.1014,  0.0140,  0.5943],\n",
              "         [ 1.0501,  0.0343,  0.4285,  0.2933, -0.2995, -0.2432, -0.0300,\n",
              "          -0.6992,  0.7993,  0.4846,  0.2376,  0.0484, -0.7183, -0.1285,\n",
              "           0.0313, -0.2238, -0.0749,  0.4793],\n",
              "         [ 0.8152,  0.2136,  0.3962,  0.3224, -0.1273, -0.2168, -0.2541,\n",
              "          -0.4810,  0.4369,  0.2927,  0.3138,  0.0792, -0.5553, -0.0028,\n",
              "           0.0056, -0.2044,  0.0563,  0.2354],\n",
              "         [ 0.7609,  0.2804,  0.4015,  0.2737, -0.0097, -0.0695, -0.1644,\n",
              "          -0.4264,  0.6622,  0.1981,  0.1975, -0.0442, -0.4324,  0.2567,\n",
              "           0.0029, -0.2155, -0.0194,  0.3436]]], grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "mha_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "3226d617",
      "metadata": {
        "id": "3226d617",
        "outputId": "49844bd2-4115-4f92-d96c-0316501ce6e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "mha_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "d78d55f0",
      "metadata": {
        "id": "d78d55f0"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "        # As in `CausalAttention`, for inputs where `num_tokens` exceeds `context_length`,\n",
        "        # this will result in errors in the mask creation further below.\n",
        "        # In practice, this is not a problem since the LLM (chapters 4-7) ensures that inputs\n",
        "        # do not exceed `context_length` before reaching this forward method.\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "55874c7d",
      "metadata": {
        "id": "55874c7d",
        "outputId": "62e25793-d61b-4e7e-94fc-7059b179d5a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "batches.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "c72fa018",
      "metadata": {
        "id": "c72fa018",
        "outputId": "2249cac4-c208-45f9-cb8d-df39fe50798e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9999, -1.2737,  0.2339,  1.1430,  1.0805, -0.2544,  1.7306,\n",
              "          -0.6830],\n",
              "         [-0.7617, -2.2307, -0.4388, -0.0068,  0.7100, -0.5587, -0.4294,\n",
              "           0.2109],\n",
              "         [-0.0450, -0.6184,  0.1731, -0.5922,  0.5761, -1.0463, -0.7864,\n",
              "          -0.6586],\n",
              "         [ 0.5506, -1.1198,  0.6035,  0.6885,  1.4914, -0.5357,  0.2084,\n",
              "           0.8669]],\n",
              "\n",
              "        [[-0.9999, -1.2737,  0.2339,  1.1430,  1.0805, -0.2544,  1.7306,\n",
              "          -0.6830],\n",
              "         [-0.7617, -2.2307, -0.4388, -0.0068,  0.7100, -0.5587, -0.4294,\n",
              "           0.2109],\n",
              "         [-0.0450, -0.6184,  0.1731, -0.5922,  0.5761, -1.0463, -0.7864,\n",
              "          -0.6586],\n",
              "         [ 0.5506, -1.1198,  0.6035,  0.6885,  1.4914, -0.5357,  0.2084,\n",
              "           0.8669]]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "2fe1dfac",
      "metadata": {
        "id": "2fe1dfac",
        "outputId": "67ff585d-be67-4140-beed-07f501c32030",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.9999, -1.2737,  0.2339,  1.1430],\n",
              "          [ 1.0805, -0.2544,  1.7306, -0.6830]],\n",
              "\n",
              "         [[-0.7617, -2.2307, -0.4388, -0.0068],\n",
              "          [ 0.7100, -0.5587, -0.4294,  0.2109]],\n",
              "\n",
              "         [[-0.0450, -0.6184,  0.1731, -0.5922],\n",
              "          [ 0.5761, -1.0463, -0.7864, -0.6586]],\n",
              "\n",
              "         [[ 0.5506, -1.1198,  0.6035,  0.6885],\n",
              "          [ 1.4914, -0.5357,  0.2084,  0.8669]]],\n",
              "\n",
              "\n",
              "        [[[-0.9999, -1.2737,  0.2339,  1.1430],\n",
              "          [ 1.0805, -0.2544,  1.7306, -0.6830]],\n",
              "\n",
              "         [[-0.7617, -2.2307, -0.4388, -0.0068],\n",
              "          [ 0.7100, -0.5587, -0.4294,  0.2109]],\n",
              "\n",
              "         [[-0.0450, -0.6184,  0.1731, -0.5922],\n",
              "          [ 0.5761, -1.0463, -0.7864, -0.6586]],\n",
              "\n",
              "         [[ 0.5506, -1.1198,  0.6035,  0.6885],\n",
              "          [ 1.4914, -0.5357,  0.2084,  0.8669]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "batches.view( 2, 4, 2, 4 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "c2ab6218",
      "metadata": {
        "id": "c2ab6218"
      },
      "outputs": [],
      "source": [
        "mha = MultiHeadAttention( d_in = 8, d_out = 6, context_length=4, dropout=0, num_heads=3 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "827eb25a",
      "metadata": {
        "id": "827eb25a"
      },
      "outputs": [],
      "source": [
        "mha_out = mha( batches )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "0b0d0409",
      "metadata": {
        "id": "0b0d0409",
        "outputId": "94bd912d-a484-43ac-9e54-cec41ed240ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.6244, -0.5975, -0.1934,  0.5200, -0.5116,  0.2835],\n",
              "         [-0.1321, -0.4701, -0.4574,  0.0414, -0.4035,  0.3737],\n",
              "         [ 0.0160, -0.3677, -0.3209,  0.0119, -0.3741,  0.3938],\n",
              "         [ 0.0414, -0.3517, -0.2693,  0.0892, -0.4068,  0.3144]],\n",
              "\n",
              "        [[-0.6244, -0.5975, -0.1934,  0.5200, -0.5116,  0.2835],\n",
              "         [-0.1321, -0.4701, -0.4574,  0.0414, -0.4035,  0.3737],\n",
              "         [ 0.0160, -0.3677, -0.3209,  0.0119, -0.3741,  0.3938],\n",
              "         [ 0.0414, -0.3517, -0.2693,  0.0892, -0.4068,  0.3144]]],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "mha_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "76c1c99f",
      "metadata": {
        "id": "76c1c99f",
        "outputId": "e42ad426-2a2a-41c2-9a91-89217646b111",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "mha_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "c57eb0ed",
      "metadata": {
        "id": "c57eb0ed"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}