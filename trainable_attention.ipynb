{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mbrudd/LLMs/blob/main/trainable_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c33a1a1",
      "metadata": {
        "id": "7c33a1a1"
      },
      "source": [
        "# Attention with trainable weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c78b079a",
      "metadata": {
        "id": "c78b079a"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d1c0c81b",
      "metadata": {
        "id": "d1c0c81b"
      },
      "outputs": [],
      "source": [
        "inputs = torch.nn.Embedding( 4, 8 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "oNX4cULRxBVk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNX4cULRxBVk",
        "outputId": "bf533d32-7ab7-4a18-9199-4831562708d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.5230, -1.0122,  0.5992, -0.2435, -0.6084, -0.4282,  1.6621,  1.3989],\n",
              "        [-0.9138, -0.6302,  0.3323, -1.3207, -0.9561, -0.4106,  0.2507, -0.2165],\n",
              "        [ 0.2848, -0.8262, -0.4451, -1.5865, -0.2796,  0.0701,  1.4476,  0.6383],\n",
              "        [ 2.1760,  0.8191, -0.5692,  0.8127,  0.9198,  0.2796, -2.0018,  1.1478]],\n",
              "       requires_grad=True)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = inputs.weight\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "sTBV2KZYxCLY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTBV2KZYxCLY",
        "outputId": "7a7441ce-d882-4b7d-8823-43e7c0d9f49d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.5230, -1.0122,  0.5992, -0.2435, -0.6084, -0.4282,  1.6621,  1.3989],\n",
              "        [-0.9138, -0.6302,  0.3323, -1.3207, -0.9561, -0.4106,  0.2507, -0.2165],\n",
              "        [ 0.2848, -0.8262, -0.4451, -1.5865, -0.2796,  0.0701,  1.4476,  0.6383],\n",
              "        [ 2.1760,  0.8191, -0.5692,  0.8127,  0.9198,  0.2796, -2.0018,  1.1478]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = inputs.data\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "QOwlthXbxb38",
      "metadata": {
        "id": "QOwlthXbxb38"
      },
      "outputs": [],
      "source": [
        "# set dimensions\n",
        "d_in = 8\n",
        "d_out = 6\n",
        "\n",
        "# create weight matrices\n",
        "W_q = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "W_k = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "W_v = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "sNXSVRxtyUEq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNXSVRxtyUEq",
        "outputId": "4fe17bbf-ced8-46dc-e34d-0fff0c6f0d3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.8374, -0.9581, -0.2278,  0.9000, -1.9623, -1.4585])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# choose an input vector and transform it into our query vector using W_q\n",
        "query = inputs[2] @ W_q\n",
        "query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "krMfHBPty33R",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krMfHBPty33R",
        "outputId": "36438707-eb94-4b85-fe7a-ccd7e92f7a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keys: tensor([[ 0.5973,  1.0044,  0.8443,  1.2623,  0.8390,  1.1659],\n",
            "        [-2.0393, -2.2555, -1.5301, -2.0293, -1.5247, -1.6047],\n",
            "        [-0.7451,  0.3819, -0.3960,  0.0507, -0.3498,  0.3000],\n",
            "        [ 2.3991,  1.8205,  2.1116,  2.6182,  1.7647,  1.2838]])\n",
            "Values: tensor([[-0.1780,  1.0546,  0.0233, -0.0530,  2.4320, -0.1252],\n",
            "        [-2.8279, -1.6676, -1.9344, -2.2037, -1.6624, -2.3033],\n",
            "        [-1.8483, -0.0499, -1.4484, -1.2959,  0.9830, -0.6364],\n",
            "        [ 2.7270,  1.7948,  0.9515,  2.9547,  1.4034,  3.0973]])\n"
          ]
        }
      ],
      "source": [
        "# calculate attention scores using the keys generated by W_k:\n",
        "keys = inputs @ W_k\n",
        "values = inputs @ W_v\n",
        "print(\"Keys:\", keys)\n",
        "print(\"Values:\", values )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ZCYUxgufzYJx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCYUxgufzYJx",
        "outputId": "7e9c9241-c8e1-4050-a98f-90c15f9784ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-3.8656,  7.7232,  0.6426, -7.2132])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_scores = query @ keys.T\n",
        "attention_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "8E3nKiYMz-B3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E3nKiYMz-B3",
        "outputId": "7be3feb4-bbc4-4b3e-93f7-f73d3592d996"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.0083, 0.9376, 0.0521, 0.0021])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_weights = torch.softmax( attention_scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "ivp5ajUU0hVX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivp5ajUU0hVX",
        "outputId": "3d728c16-7da8-47e1-9f90-dfe88ae97494"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.0000)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_weights.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "NDyjIXnw01bw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDyjIXnw01bw",
        "outputId": "77c652e1-60bf-4708-b3ab-3b48762a4538"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-2.7433, -1.5535, -1.8868, -2.1278, -1.4844, -2.1871])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context_vector = attention_weights @ values\n",
        "context_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "mDJu60I-08oe",
      "metadata": {
        "id": "mDJu60I-08oe"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "nCNgyvAjDqJx",
      "metadata": {
        "id": "nCNgyvAjDqJx"
      },
      "outputs": [],
      "source": [
        "# here's a first version of a SimpleAttention class:\n",
        "\n",
        "class SimpleAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "    self.W_k = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "    self.W_v = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    queries = x @ self.W_q\n",
        "    keys = x @ self.W_k\n",
        "    values = x @ self.W_v\n",
        "    scores = queries @ keys.T\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    context = weights @ values\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "WGqfizBVGQ6H",
      "metadata": {
        "id": "WGqfizBVGQ6H"
      },
      "outputs": [],
      "source": [
        "# here's how to use this class:\n",
        "# instantiate an instance of it:\n",
        "simple = SimpleAttention( d_in = 8, d_out = 6 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "m8khSsLLGbPx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8khSsLLGbPx",
        "outputId": "83c97ed1-6c15-4aa0-c1aa-2b1c9817df8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.7287, 0.5747, 0.2106, 0.4504, 0.4743, 0.4702],\n",
              "        [0.1476, 0.5786, 0.3352, 0.0245, 0.5461, 0.7167],\n",
              "        [0.3128, 0.0113, 0.8220, 0.5390, 0.3141, 0.9862],\n",
              "        [0.8924, 0.0380, 0.2893, 0.5757, 0.9561, 0.8739],\n",
              "        [0.1583, 0.0510, 0.8964, 0.8533, 0.6959, 0.1652],\n",
              "        [0.1750, 0.0867, 0.7179, 0.8085, 0.5043, 0.2204],\n",
              "        [0.7321, 0.7470, 0.2207, 0.3066, 0.3434, 0.6393],\n",
              "        [0.2751, 0.8343, 0.7991, 0.8217, 0.0969, 0.2075]])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simple.W_v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "IDXEWBn2GhTu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDXEWBn2GhTu",
        "outputId": "d9483eba-77bf-4458-acdc-1363e90757a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.5050,  1.8708,  1.0198,  1.4026,  0.1885,  0.9595],\n",
              "        [-1.9265, -1.0054, -1.7768, -2.2492, -2.7388, -1.8386],\n",
              "        [-1.5324, -0.5458, -1.4648, -1.8090, -2.4616, -1.6337],\n",
              "        [ 1.2995,  1.2851,  1.9965,  2.4966,  2.2737,  0.9313]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context_vectors = simple( inputs )\n",
        "context_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "j0J4KZOZGqfu",
      "metadata": {
        "id": "j0J4KZOZGqfu"
      },
      "outputs": [],
      "source": [
        "# here's a second version of a SimpleAttention class ;\n",
        "# it uses nn.Linear to do things more efficiently\n",
        "\n",
        "class SimpleAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    queries = self.W_q( x )\n",
        "    keys = self.W_k( x )\n",
        "    values = self.W_v( x )\n",
        "    scores = queries @ keys.T\n",
        "\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    context = weights @ values\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "Zki5jtLCI6Cu",
      "metadata": {
        "id": "Zki5jtLCI6Cu"
      },
      "outputs": [],
      "source": [
        "# here's how to use this class:\n",
        "# instantiate an instance of it:\n",
        "simple = SimpleAttention( d_in = 8, d_out = 6 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "k6LcTWL9I8te",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6LcTWL9I8te",
        "outputId": "f4f6f2d6-079c-4c85-9210-7a3c6bf76b02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.1243,  0.1402, -0.2909, -0.2067, -0.0791, -0.0674],\n",
              "        [ 0.0919,  0.1422, -0.2992, -0.2242, -0.0921, -0.0729],\n",
              "        [-0.0217,  0.1702, -0.3123, -0.2852, -0.1456, -0.0821],\n",
              "        [ 0.3033,  0.1649, -0.2265, -0.0965, -0.0174, -0.0170]],\n",
              "       grad_fn=<MmBackward0>)"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context_vectors = simple( inputs )\n",
        "context_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "oue7IwuyI_ON",
      "metadata": {
        "id": "oue7IwuyI_ON"
      },
      "outputs": [],
      "source": [
        "# the problem with this is that each context vector uses information from ALL of the embedding vectors\n",
        "# in practice, we should only use information about the preceding embedding vectors\n",
        "# to accomplish this, we'll implement causal attention AKA masked attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "L734IABHc89l",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L734IABHc89l",
        "outputId": "d3baf755-2800-4380-d368-aca36fc58adb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.1243,  0.1402, -0.2909, -0.2067, -0.0791, -0.0674],\n",
              "        [ 0.0919,  0.1422, -0.2992, -0.2242, -0.0921, -0.0729],\n",
              "        [-0.0217,  0.1702, -0.3123, -0.2852, -0.1456, -0.0821],\n",
              "        [ 0.3033,  0.1649, -0.2265, -0.0965, -0.0174, -0.0170]],\n",
              "       grad_fn=<MmBackward0>)"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# this is a hack to get some example weights to work with!\n",
        "weights = simple( inputs )\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "SiNiJA_tdnIr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiNiJA_tdnIr",
        "outputId": "a0b95c43-6209-4884-ef27-c09babf578a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.3796, -0.4543, -0.6767,  0.1107], grad_fn=<SumBackward1>)"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# note that these have already been normalized:\n",
        "weights.sum( dim=-1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "w8qwVBb3d5YE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8qwVBb3d5YE",
        "outputId": "91908225-ad9d-429f-9feb-41559e43afcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0.],\n",
              "        [1., 1., 0., 0.],\n",
              "        [1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# masking method #1\n",
        "simple_mask = torch.tril( torch.ones( weights.shape[0], weights.shape[0] ) )\n",
        "simple_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "aPN1GiEdeWq_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPN1GiEdeWq_",
        "outputId": "076493fd-32eb-4fbb-fb27-2d71ed7c8da9"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (6) must match the size of tensor b (4) at non-singleton dimension 1",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m masked_weights = \u001b[43mweights\u001b[49m\u001b[43m*\u001b[49m\u001b[43msimple_mask\u001b[49m\n\u001b[32m      2\u001b[39m masked_weights\n",
            "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (6) must match the size of tensor b (4) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "masked_weights = weights*simple_mask\n",
        "masked_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "N-Ifwx0EfJs9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-Ifwx0EfJs9",
        "outputId": "ac5c40b5-443a-4b61-b330-7e09933e052a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'masked_weights' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmasked_weights\u001b[49m.sum( dim=-\u001b[32m1\u001b[39m )\n",
            "\u001b[31mNameError\u001b[39m: name 'masked_weights' is not defined"
          ]
        }
      ],
      "source": [
        "masked_weights.sum( dim=-1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "gbOrqXGSfbm2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbOrqXGSfbm2",
        "outputId": "776e5184-5094-459f-82bb-c71d1a27612b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'masked_weights' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# now, we need to normalize the masked_weights so that each row has sum 1\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m row_sums = \u001b[43mmasked_weights\u001b[49m.sum( dim=-\u001b[32m1\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m row_sums\n",
            "\u001b[31mNameError\u001b[39m: name 'masked_weights' is not defined"
          ]
        }
      ],
      "source": [
        "# now, we need to normalize the masked_weights so that each row has sum 1\n",
        "row_sums = masked_weights.sum( dim=-1, keepdim=True)\n",
        "row_sums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ACdob5jyfi2P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACdob5jyfi2P",
        "outputId": "ac8441ef-1062-437a-d640-31efeb9c7a6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "masked_weights = masked_weights / row_sums\n",
        "masked_weights.sum( dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0_aQEYcQf4tB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_aQEYcQf4tB",
        "outputId": "bc7275db-146c-4e00-d521-ceb4b0abdd29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5437, 0.4563, 0.0000, 0.0000],\n",
              "        [0.2536, 0.3010, 0.4455, 0.0000],\n",
              "        [0.2878, 0.2422, 0.2345, 0.2355]], grad_fn=<DivBackward0>)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "masked_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QxaUROkpgBmr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxaUROkpgBmr",
        "outputId": "19c68189-cc59-4e7e-88fd-13116854c6ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1.],\n",
              "        [0., 0., 1., 1.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# masking method #2\n",
        "mask = torch.triu( torch.ones(weights.shape[0], weights.shape[0]), diagonal = 1 )\n",
        "mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aAkggNUhUAs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aAkggNUhUAs",
        "outputId": "01ca9d8c-e586-4301-b5c6-fc8fc6a85875"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[False,  True,  True,  True],\n",
              "        [False, False,  True,  True],\n",
              "        [False, False, False,  True],\n",
              "        [False, False, False, False]])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mask.bool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84ev4pTZhoLD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84ev4pTZhoLD",
        "outputId": "dc355d81-9336-457d-af14-4b7d03cf728b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.2687, 0.2787, 0.1943, 0.2583],\n",
              "        [0.3065, 0.2572, 0.1634, 0.2729],\n",
              "        [0.1916, 0.2275, 0.3366, 0.2443],\n",
              "        [0.2878, 0.2422, 0.2345, 0.2355]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7AW_dLvCgiA8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AW_dLvCgiA8",
        "outputId": "201749c3-b038-4aeb-cad3-680f612701a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.2687,   -inf,   -inf,   -inf],\n",
              "        [0.3065, 0.2572,   -inf,   -inf],\n",
              "        [0.1916, 0.2275, 0.3366,   -inf],\n",
              "        [0.2878, 0.2422, 0.2345, 0.2355]], grad_fn=<MaskedFillBackward0>)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights = weights.masked_fill( mask.bool(), -torch.inf )\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mMquJ-g1hvuq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMquJ-g1hvuq",
        "outputId": "832c13f1-13fb-43a7-db07-0703b88cdedd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5123, 0.4877, 0.0000, 0.0000],\n",
              "        [0.3132, 0.3247, 0.3621, 0.0000],\n",
              "        [0.2596, 0.2480, 0.2461, 0.2463]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "masked_weights = torch.softmax( weights, dim=-1 )\n",
        "masked_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v0Rl7yaikQwW",
      "metadata": {
        "id": "v0Rl7yaikQwW"
      },
      "outputs": [],
      "source": [
        "## Dropout\n",
        "# idea: randomly select some data to leave out to avoid overfitting\n",
        "dropout = nn.Dropout( 0.5 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Js4JQ6b9lN1p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js4JQ6b9lN1p",
        "outputId": "1ce7a802-c040-47a4-93a1-3fb39248b5a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.4922, 0.4927]], grad_fn=<MulBackward0>)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dropout( masked_weights )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lwzL1olBjA62",
      "metadata": {
        "id": "lwzL1olBjA62"
      },
      "outputs": [],
      "source": [
        "# we need to be able to give our LLM batches of input\n",
        "# for example:\n",
        "batches = torch.stack( (inputs, inputs), dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F9pE07dKjkPS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9pE07dKjkPS",
        "outputId": "7c8abc7d-055c-4f1d-e79a-808d8df996a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.2427,  0.6827,  0.7656,  1.0912,  1.2138,  0.6371, -0.5461,\n",
              "          -0.3942],\n",
              "         [-1.4937,  1.5845,  2.5122, -0.6860,  0.8015, -1.1129, -0.2717,\n",
              "           0.0380],\n",
              "         [-0.1699, -0.4934, -1.0443,  1.7926, -0.5786, -0.3779,  0.4462,\n",
              "           0.0745],\n",
              "         [-0.0711,  1.5781,  1.1288, -1.0967,  0.1295,  0.0320,  0.7134,\n",
              "           0.6368]],\n",
              "\n",
              "        [[-0.2427,  0.6827,  0.7656,  1.0912,  1.2138,  0.6371, -0.5461,\n",
              "          -0.3942],\n",
              "         [-1.4937,  1.5845,  2.5122, -0.6860,  0.8015, -1.1129, -0.2717,\n",
              "           0.0380],\n",
              "         [-0.1699, -0.4934, -1.0443,  1.7926, -0.5786, -0.3779,  0.4462,\n",
              "           0.0745],\n",
              "         [-0.0711,  1.5781,  1.1288, -1.0967,  0.1295,  0.0320,  0.7134,\n",
              "           0.6368]]])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZcupJCg5zIrL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcupJCg5zIrL",
        "outputId": "f0a40051-1080-4e1d-caeb-e49b1b2f9974"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 8])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batches.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uP2PuQ5RiCM8",
      "metadata": {
        "id": "uP2PuQ5RiCM8"
      },
      "outputs": [],
      "source": [
        "# this class needs to handle batches of input!\n",
        "\n",
        "class CausalAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
        "    # include dropout:\n",
        "    self.dropout = nn.Dropout( dropout )\n",
        "    # use the following to manage memory efficiently:\n",
        "    self.register_buffer(\n",
        "        'mask',\n",
        "        torch.triu( torch.ones(context_length, context_length), diagonal = 1 )\n",
        "    )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    queries = self.W_q( x )\n",
        "    keys = self.W_k( x )\n",
        "    values = self.W_v( x )\n",
        "    scores = queries @ keys.transpose(1,2)\n",
        "    scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    weights = self.dropout( weights )\n",
        "    context = weights @ values\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Tqglx-lp0TFn",
      "metadata": {
        "id": "Tqglx-lp0TFn"
      },
      "outputs": [],
      "source": [
        "# instantiate a causal attention mechanism:\n",
        "causal = CausalAttention( d_in=8, d_out=6, context_length=4, dropout=0 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vl4s2kdd4iNi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl4s2kdd4iNi",
        "outputId": "020a098a-31b7-47c1-ef07-df80ddf5713f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.2956,  0.1039,  0.0676, -0.2119, -0.7519, -0.4160],\n",
              "         [ 0.0174, -0.0664, -0.5165, -0.7360, -1.3500, -0.3612],\n",
              "         [-0.4007,  0.0280, -0.0891, -0.4656, -0.5094, -0.2803],\n",
              "         [ 0.0916, -0.1431, -0.1039, -0.6458, -0.7593, -0.2148]],\n",
              "\n",
              "        [[-0.2956,  0.1039,  0.0676, -0.2119, -0.7519, -0.4160],\n",
              "         [ 0.0174, -0.0664, -0.5165, -0.7360, -1.3500, -0.3612],\n",
              "         [-0.4007,  0.0280, -0.0891, -0.4656, -0.5094, -0.2803],\n",
              "         [ 0.0916, -0.1431, -0.1039, -0.6458, -0.7593, -0.2148]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "causal( batches )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sqLa6xcW0bPw",
      "metadata": {
        "id": "sqLa6xcW0bPw"
      },
      "outputs": [],
      "source": [
        "# everything below is just to show what happens with batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TxE4RKo20-h0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxE4RKo20-h0",
        "outputId": "cb5d6181-0c7d-4589-ed84-5d48c6acef6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-3.2929e-02, -5.1089e-02,  1.9729e-01,  1.4060e-01,  1.1246e-03,\n",
              "           2.1223e-01],\n",
              "         [ 1.2751e+00,  1.2309e+00, -2.6176e-01,  1.3619e+00,  5.4810e-01,\n",
              "          -1.9892e-01],\n",
              "         [-7.6839e-01,  8.0788e-02,  5.8067e-01, -1.6036e-01, -8.1724e-01,\n",
              "           7.5022e-01],\n",
              "         [ 8.3302e-01,  6.2428e-01,  8.5691e-04,  7.7048e-01,  3.1241e-01,\n",
              "          -4.3753e-01]],\n",
              "\n",
              "        [[-3.2929e-02, -5.1089e-02,  1.9729e-01,  1.4060e-01,  1.1246e-03,\n",
              "           2.1223e-01],\n",
              "         [ 1.2751e+00,  1.2309e+00, -2.6176e-01,  1.3619e+00,  5.4810e-01,\n",
              "          -1.9892e-01],\n",
              "         [-7.6839e-01,  8.0788e-02,  5.8067e-01, -1.6036e-01, -8.1724e-01,\n",
              "           7.5022e-01],\n",
              "         [ 8.3302e-01,  6.2428e-01,  8.5691e-04,  7.7048e-01,  3.1241e-01,\n",
              "          -4.3753e-01]]], grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "queries = W_q( batches )\n",
        "queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oXOqIeOi0_pX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXOqIeOi0_pX",
        "outputId": "1cbcc53f-dcb1-43e6-8e33-3e894ede0feb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.2261, -0.3120,  0.0810, -0.2931, -0.8426, -0.4877],\n",
              "         [ 0.0451, -0.1597,  0.1095,  0.7858, -0.6787, -0.8029],\n",
              "         [ 0.4853,  0.2652, -0.1591, -0.0825,  0.7799,  0.3343],\n",
              "         [-0.5785, -0.2767,  0.4855,  0.1878, -0.5316, -0.8584]],\n",
              "\n",
              "        [[ 0.2261, -0.3120,  0.0810, -0.2931, -0.8426, -0.4877],\n",
              "         [ 0.0451, -0.1597,  0.1095,  0.7858, -0.6787, -0.8029],\n",
              "         [ 0.4853,  0.2652, -0.1591, -0.0825,  0.7799,  0.3343],\n",
              "         [-0.5785, -0.2767,  0.4855,  0.1878, -0.5316, -0.8584]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keys = W_k( batches )\n",
        "keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "skDtU7a31bAS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skDtU7a31bAS",
        "outputId": "3498b8a9-fde1-47b2-ab74-84e61e23cdca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.2261,  0.0451,  0.4853, -0.5785],\n",
              "         [-0.3120, -0.1597,  0.2652, -0.2767],\n",
              "         [ 0.0810,  0.1095, -0.1591,  0.4855],\n",
              "         [-0.2931,  0.7858, -0.0825,  0.1878],\n",
              "         [-0.8426, -0.6787,  0.7799, -0.5316],\n",
              "         [-0.4877, -0.8029,  0.3343, -0.8584]],\n",
              "\n",
              "        [[ 0.2261,  0.0451,  0.4853, -0.5785],\n",
              "         [-0.3120, -0.1597,  0.2652, -0.2767],\n",
              "         [ 0.0810,  0.1095, -0.1591,  0.4855],\n",
              "         [-0.2931,  0.7858, -0.0825,  0.1878],\n",
              "         [-0.8426, -0.6787,  0.7799, -0.5316],\n",
              "         [-0.4877, -0.8029,  0.3343, -0.8584]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keys.transpose(1,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4-NOY2s91p61",
      "metadata": {
        "id": "4-NOY2s91p61"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
